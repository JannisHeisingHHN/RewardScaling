[setup]

device = ["cuda:3", "cuda:0"]
use_mlflow = true
mlflow_run_name = "Single-Plain-SmoothL1Loss"

mlflow_uri = "http://10.30.20.11:5000"
mlflow_experiment = "jheis_SRL_MountainCar-v0"


[parameters] # these are logged in mlflow

# environment
env = {id = "MountainCar-v0", max_episode_steps = 500}
num_envs = 11

# model architecture (excluding input & output size since these are determined by the environment)
# because TOML doesn't support heterogeneous arrays, all entries must be strings, which are passed through eval()
architecture_hidden = ["256", "nn.BatchNorm1d(256)", "256"]

# training lengths
n_episodes = 7000
n_steps_per_episode = 500
n_train_epochs = 5 # training cycles per epoch
batch_size = 1013

# model parameters
model_class = "SingleLearner"
target_update = 0.9
use_reward_scaling = false

# Custom reward as python code; must include a function "custom_reward(state, action, game_reward, terminated) -> NDArray"
# Is passed through exec(). Due to toml weirdness a docstring is not (easily) possible; put an explanation in the "custom_reward_doc" field below
custom_reward = """
def custom_reward(state, action, game_reward, terminated):
    x_pos = state[:, 0]                 # x-position of cart
    y_pos = np.sin(3 * x_pos)           # y-position of cart
    pos_reward = ((y_pos + 1) / 2)**2   # give reward based on cart position
    flag_bonus = 2 * (x_pos >= 0.5)     # reward for reaching the flag (essentially the game reward), scaled so it's always greater than the position reward
    reward = pos_reward + flag_bonus

    return reward
"""
custom_reward_doc = "reward = ((y_pos + 1) / 2)^2 + flag_bonus"

# variable parameters
gamma = {start = 0.9, end = 0.9, midpoint = 2500, rate = 0.0015}    # discount factor
epsilon = {start = 1, end = 0.05, midpoint = 2000, rate = 0.001}    # chance for random action
learning_rate = {start = 3e-4, factor = 0.9997}                     # learning rate (exponential decay)

# replay buffer
replay_buffer_size = 100_000

# save parameters
start_episode = 0
save_interval = 100
save_path = "weights/mountaincar/single_plain"
