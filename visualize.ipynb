{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096eab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tc\n",
    "from torch import nn\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from agents import *\n",
    "from envs import *\n",
    "from train import obs_to_state\n",
    "\n",
    "import mlflow\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import toml\n",
    "\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select settings path\n",
    "path_settings = \"settings_pendulum.toml\"\n",
    "\n",
    "# read from settings\n",
    "settings = toml.load(path_settings)\n",
    "params = settings['parameters']\n",
    "path_weight = params['save_path']\n",
    "env_params = params['env']\n",
    "Model: type[Learner] = eval(params['model_class'])\n",
    "discretise: int | bool = params.get('discretise', False)\n",
    "\n",
    "# select settings\n",
    "EPOCH = 300\n",
    "SHOW_WINDOW = True\n",
    "env_params['max_episode_steps'] = 100\n",
    "N_EPISODES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose render mode\n",
    "if SHOW_WINDOW:\n",
    "    env_params['render_mode'] = \"human\"\n",
    "\n",
    "# create environment generator\n",
    "env_generator = (\n",
    "        (lambda: DiscretiseAction(gym.make(**params['env']), n_actions=discretise))\n",
    "    if isinstance(discretise, int) else\n",
    "        (lambda: gym.make(**params['env']))\n",
    ")\n",
    "\n",
    "# create environment (using a SyncVectorEnv to be consistent with training; not necessary)\n",
    "env_vis = gym.vector.SyncVectorEnv([env_generator])\n",
    "\n",
    "# load agent from checkpoint\n",
    "with tc.serialization.safe_globals([nn.BatchNorm1d]):\n",
    "    agent_vis = Model.load(path_weight, EPOCH, DEVICE)\n",
    "agent_vis.eval()\n",
    "\n",
    "# create action lookup\n",
    "n_actions = int(env_vis.action_space.nvec[0]) # type: ignore\n",
    "actions_onehot = tc.eye(n_actions, dtype=tc.int, device=agent_vis.device)\n",
    "\n",
    "# keep track of states & actions\n",
    "states = []\n",
    "actions = []\n",
    "\n",
    "# reset environment\n",
    "observation, info = env_vis.reset() \n",
    "\n",
    "\n",
    "tqdm_iter = trange(env_params['max_episode_steps'] * N_EPISODES)\n",
    "for t in tqdm_iter:\n",
    "    with tc.no_grad():\n",
    "        state = obs_to_state(observation, DEVICE)\n",
    "\n",
    "        action = agent_vis.act(state, actions_onehot)\n",
    "\n",
    "    # update progress bar title\n",
    "    tqdm_iter.set_description(f\"Chose action {action}\")\n",
    "\n",
    "    # perform step\n",
    "    observation, reward, terminated, truncated, info = env_vis.step(action)\n",
    "\n",
    "    # store state & action\n",
    "    states.append(state)\n",
    "    actions.append(float(action.item()))\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env_vis.reset()\n",
    "\n",
    "env_vis.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tc.nn.utils.parameters_to_vector(agent_vis.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.nn.utils.vector_to_parameters(v, agent_vis.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vis.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2367bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(actions, bins=50)\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(states)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e26c99",
   "metadata": {},
   "source": [
    "# Metric retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://10.30.20.11:5000\")\n",
    "mlflow.set_experiment(\"jheis_SRL_MountainCar-v0\")\n",
    "\n",
    "client = mlflow.tracking.MlflowClient() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"f70604c2f06147de9d7577b04016208a\"\n",
    "\n",
    "get_history = lambda name: np.array(list(map(lambda x: x.value, client.get_metric_history(run_id, name))))\n",
    "\n",
    "history_lq1 = get_history(\"loss_q1\")\n",
    "history_lq2 = get_history(\"loss_q2\")\n",
    "history_el = get_history(\"episode_length\")\n",
    "history_q = get_history(\"q\")\n",
    "history_reward = get_history(\"mean_reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66249b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "xmin = 0\n",
    "xmax = len(history_q) - 1\n",
    "plt.hlines([0], xmin, xmax, colors=\"black\")\n",
    "# plt.plot(history_lq1, label=\"Q loss\")\n",
    "plt.plot(history_q, label=\"Q value\")\n",
    "plt.plot(history_reward, label=\"Reward\")\n",
    "# plt.plot(history_el > 200)\n",
    "# plt.plot(history_reward)\n",
    "# plt.semilogy()\n",
    "# plt.ylim(38, 40)\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"SAC training metrics\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af709e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymnasium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
